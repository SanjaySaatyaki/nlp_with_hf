{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvN899HV3hyyuZadoclrbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjaySaatyaki/nlp_with_hf/blob/main/2_txt_classfication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "gVb-8wyJh5Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "ka8MDh-0b0uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = load_dataset(\"emotion\")\n",
        "emotions"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oWGpyX43cWca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "GaH432cOdInd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds  = emotions[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "id": "0AP3BazOde8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "id": "Gp9qSCd7dvv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "id": "uB1OGxREYbaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.features"
      ],
      "metadata": {
        "id": "nOEh9PEgYd2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:5]"
      ],
      "metadata": {
        "id": "VGqVCah5YmAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions[\"train\"].features[\"label\"]"
      ],
      "metadata": {
        "id": "ZwAJvpphYu5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Zzy4LhSUaZms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row):\n",
        "  return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)"
      ],
      "metadata": {
        "id": "8vx7EyflaJ0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "k9L3_Y3yapDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jz6cOKr4ap-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Words_per_tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "\n",
        "df.boxplot(\"Words_per_tweet\", by=\"label_name\", grid=False,showfliers=False, color=\"black\")\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5VDPid5PbF2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "UarcqSefch5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "Hp4JZvWqc1Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"Tokenizing text is a core task of NLP\"\n",
        "encoded_text = tokenizer(text)"
      ],
      "metadata": {
        "id": "IkeSHFkEi76K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "06bVtb-HjnPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "KYcFWRwTkKYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "n_Hk1ZCuldsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers as Feature Extrators"
      ],
      "metadata": {
        "id": "0RNsrp6Wsl31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "5woapvMwoSij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"this is a test sentence\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"Inputs: {inputs['input_ids'].size()}\")"
      ],
      "metadata": {
        "id": "TY6oP_hWtl2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "GhPp-bpYwHgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state.size()"
      ],
      "metadata": {
        "id": "Acf5EotdxMtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hidden_states(batch):\n",
        "  inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = model(**inputs).last_hidden_state\n",
        "  return {\"hidden_state\":last_hidden_state[:,0].cpu().numpy()}\n"
      ],
      "metadata": {
        "id": "rgDfYlLXxR9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_input_names"
      ],
      "metadata": {
        "id": "O_jP92qgoF-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])"
      ],
      "metadata": {
        "id": "9KUCKqPPoSr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
      ],
      "metadata": {
        "id": "2vL5be-6r_P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
        "X_train.shape, X_valid.shape"
      ],
      "metadata": {
        "id": "SsT85Dk5sEhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "mapper = UMAP(n_components=2,metric=\"cosine\").fit(X_scaled)\n",
        "df_emb = pd.DataFrame(mapper.embedding_,columns=[\"X\",\"Y\"])\n",
        "df_emb[\"label\"] = y_train\n",
        "df_emb.head()"
      ],
      "metadata": {
        "id": "obwHrN19v41n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2,3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\",\"Blues\",\"Oranges\",\"Reds\",\"Purples\",\"Greens\"]\n",
        "labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "for i,(label, cmap) in enumerate(zip(labels, cmaps)):\n",
        "  df_emb_sub = df_emb.query(f\"label == {i}\")\n",
        "  axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap, gridsize=20, linewidths=(0,))\n",
        "  axes[i].set_title(label)\n",
        "  axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2NyboxkdweVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter=3000)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_clf.score(X_valid, y_valid)\n"
      ],
      "metadata": {
        "id": "Uwjv7kx1z-2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "bRcKwlE21lvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "  fig, ax = plt.subplots(figsize=(6,6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap=\"Blues\",values_format=\".2f\", ax=ax, colorbar=False)\n",
        "  plt.title(\"Normalized Confusion Matrix\")\n",
        "  plt.show()\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, labels)"
      ],
      "metadata": {
        "id": "qQd30NG4189f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finetuning Transformers"
      ],
      "metadata": {
        "id": "RizWBDoH-cPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 6\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)"
      ],
      "metadata": {
        "id": "cs2mTGjQ3G6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\":f1}"
      ],
      "metadata": {
        "id": "CvnqfNxw_VuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_name,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy = \"epoch\",\n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=False,\n",
        "    log_level=\"error\"\n",
        ")"
      ],
      "metadata": {
        "id": "xPO4-QIJAdXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model, args= training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset= emotions_encoded[\"train\"],\n",
        "                  eval_dataset= emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "aytrcnVuBzTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Error Analysis"
      ],
      "metadata": {
        "id": "nQ7gMwoWE7Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def forward_pass_with_label(batch):\n",
        "  inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
        "  with torch.no_grad():\n",
        "    output = model(**inputs)\n",
        "    pred_label = torch.argmax(output.logits, axis=-1)\n",
        "    loss = cross_entropy(output.logits, batch[\"label\"].to(device), reduction=\"none\")\n",
        "\n",
        "  return {\"loss\":loss.cpu().numpy(),\n",
        "          \"predicted_label\":pred_label.cpu().numpy()}"
      ],
      "metadata": {
        "id": "rkREXRwhC3aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"torch\",columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
        "\n",
        "emotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(forward_pass_with_label,batched=True, batch_size=16)"
      ],
      "metadata": {
        "id": "CynTPmGlG-OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"pandas\")\n",
        "cols = [\"text\",\"label\",\"predicted_label\",\"loss\"]\n",
        "df_test= emotions_encoded[\"validation\"][:][cols]\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str)\n",
        "df_test[\"predicted_label\"] = df_test[\"predicted_label\"].apply(label_int2str)"
      ],
      "metadata": {
        "id": "ZeCt1oVdHVX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values(\"loss\", ascending=False).head(10)"
      ],
      "metadata": {
        "id": "rwiVtaIbHx-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgZ7tNAWH3PQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}